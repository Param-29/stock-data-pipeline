{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c56cbc9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession, types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5880e654",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/13 11:58:09 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .appName('test') \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43582729",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4bb930f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df = spark.read \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .parquet('data/price_n_volume/2021/AAPL.parquet')\\\n",
    "    .drop('__index_level_0__')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e8892f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- date: timestamp (nullable = true)\n",
      " |-- open: double (nullable = true)\n",
      " |-- high: double (nullable = true)\n",
      " |-- low: double (nullable = true)\n",
      " |-- close: double (nullable = true)\n",
      " |-- adjusted_close: double (nullable = true)\n",
      " |-- volume: long (nullable = true)\n",
      " |-- dividend_amount: double (nullable = true)\n",
      " |-- split_coefficient: double (nullable = true)\n",
      " |-- close_percent_change: double (nullable = true)\n",
      " |-- company: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e4ea2f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|company|count|\n",
      "+-------+-----+\n",
      "|   AAPL|  252|\n",
      "+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "df.select(\\\n",
    "          col(\"company\")\n",
    "    ).groupBy('company').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1123dd20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# source: https://stackoverflow.com/questions/71038595/pyspark-cumulative-sum-within-partition-for-moving-last-2-n-rows\n",
    "from pyspark.sql import functions as F, Window\n",
    "\n",
    "w = Window.partitionBy('company').orderBy('date').rowsBetween(Window.currentRow, 2)\n",
    "\n",
    "df = df.withColumn(\n",
    "    'close_percent_change_new', \n",
    "    F.avg('close_percent_change').over(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1fbbe18a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+------+--------+-------+------+----------------+---------+---------------+-----------------+--------------------+-------+------------------------+\n",
      "|               date|  open|    high|    low| close|  adjusted_close|   volume|dividend_amount|split_coefficient|close_percent_change|company|close_percent_change_new|\n",
      "+-------------------+------+--------+-------+------+----------------+---------+---------------+-----------------+--------------------+-------+------------------------+\n",
      "|2021-01-04 00:00:00|133.52|133.6116| 126.76|129.41|127.519519957544|143301887|            0.0|              1.0|             -2.4719|   AAPL|                 -1.5339|\n",
      "|2021-01-05 00:00:00|128.89|  131.74| 128.43|131.01|129.096146431016| 97664898|            0.0|              1.0|              1.2364|   AAPL|     0.42749999999999994|\n",
      "|2021-01-06 00:00:00|127.72|131.0499|126.382| 126.6|124.750569713508|155087970|            0.0|              1.0|             -3.3662|   AAPL|     0.30306666666666665|\n",
      "|2021-01-07 00:00:00|128.36|  131.63| 127.86|130.92|129.007461191883|109578157|            0.0|              1.0|              3.4123|   AAPL|      0.6501666666666668|\n",
      "|2021-01-08 00:00:00|132.43|  132.63| 130.23|132.05|130.120953638773|105158245|            0.0|              1.0|              0.8631|   AAPL|     -0.5337999999999999|\n",
      "|2021-01-11 00:00:00|129.19|  130.17|  128.5|128.98|127.095801592798|100620880|            0.0|              1.0|             -2.3249|   AAPL|                 -0.2806|\n",
      "|2021-01-12 00:00:00| 128.5|  129.69| 126.86| 128.8|126.918431114532| 90440255|            0.0|              1.0|             -0.1396|   AAPL|    -0.00986666666666...|\n",
      "|2021-01-13 00:00:00|128.76|  131.45| 128.49|130.89|128.977899445506| 88636831|            0.0|              1.0|              1.6227|   AAPL|     -0.4210333333333333|\n",
      "|2021-01-14 00:00:00| 130.8|   131.0| 128.76|128.91|127.026824184584| 90221755|            0.0|              1.0|             -1.5127|   AAPL|     -0.7810333333333332|\n",
      "|2021-01-15 00:00:00|128.78|130.2242|  127.0|127.14|125.282681148305|111598531|            0.0|              1.0|             -1.3731|   AAPL|                  0.8184|\n",
      "|2021-01-19 00:00:00|127.78|  128.71|126.938|127.83| 125.96260131499| 90757329|            0.0|              1.0|              0.5427|   AAPL|      2.4980333333333333|\n",
      "|2021-01-20 00:00:00|128.66|  132.49| 128.55|132.03|130.101245807855|104319489|            0.0|              1.0|              3.2856|   AAPL|       2.852933333333333|\n",
      "|2021-01-21 00:00:00| 133.8|  139.67| 133.59|136.87|134.870540890109|120529544|            0.0|              1.0|              3.6658|   AAPL|      2.6805333333333334|\n",
      "|2021-01-22 00:00:00|136.28|  139.85| 135.02|139.07|137.038402291134|114459360|            0.0|              1.0|              1.6074|   AAPL|      1.5145666666666668|\n",
      "|2021-01-25 00:00:00|143.07|  145.09| 136.54|142.92|140.832159742927|157611713|            0.0|              1.0|              2.7684|   AAPL|      0.7226333333333335|\n",
      "|2021-01-26 00:00:00| 143.6|   144.3| 141.37|143.16|141.068653713948| 98390555|            0.0|              1.0|              0.1679|   AAPL|     -1.3663333333333334|\n",
      "|2021-01-27 00:00:00|143.43|   144.3| 140.41|142.06|139.984723013435|140843759|            0.0|              1.0|             -0.7684|   AAPL|     -2.6696666666666666|\n",
      "|2021-01-28 00:00:00|139.52|  141.99|  136.7|137.09|135.087327030211|142621128|            0.0|              1.0|             -3.4985|   AAPL|      -1.862866666666667|\n",
      "|2021-01-29 00:00:00|135.83|  136.74| 130.21|131.96| 130.03226839964|177523812|            0.0|              1.0|             -3.7421|   AAPL|    -0.48546666666666677|\n",
      "|2021-02-01 00:00:00|133.75|  135.38| 130.93|134.14|132.180421969747|106239823|            0.0|              1.0|               1.652|   AAPL|      0.5026333333333333|\n",
      "+-------------------+------+--------+-------+------+----------------+---------+---------------+-----------------+--------------------+-------+------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "17e33ed1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>adjusted_close</th>\n",
       "      <th>volume</th>\n",
       "      <th>dividend_amount</th>\n",
       "      <th>split_coefficient</th>\n",
       "      <th>close_percent_change</th>\n",
       "      <th>company</th>\n",
       "      <th>close_percent_change_new</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-01-04</td>\n",
       "      <td>133.52</td>\n",
       "      <td>133.6116</td>\n",
       "      <td>126.760</td>\n",
       "      <td>129.41</td>\n",
       "      <td>127.519520</td>\n",
       "      <td>143301887</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-2.4719</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>-1.533900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-01-05</td>\n",
       "      <td>128.89</td>\n",
       "      <td>131.7400</td>\n",
       "      <td>128.430</td>\n",
       "      <td>131.01</td>\n",
       "      <td>129.096146</td>\n",
       "      <td>97664898</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.2364</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>0.427500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-01-06</td>\n",
       "      <td>127.72</td>\n",
       "      <td>131.0499</td>\n",
       "      <td>126.382</td>\n",
       "      <td>126.60</td>\n",
       "      <td>124.750570</td>\n",
       "      <td>155087970</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-3.3662</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>0.303067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-01-07</td>\n",
       "      <td>128.36</td>\n",
       "      <td>131.6300</td>\n",
       "      <td>127.860</td>\n",
       "      <td>130.92</td>\n",
       "      <td>129.007461</td>\n",
       "      <td>109578157</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.4123</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>0.650167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-01-08</td>\n",
       "      <td>132.43</td>\n",
       "      <td>132.6300</td>\n",
       "      <td>130.230</td>\n",
       "      <td>132.05</td>\n",
       "      <td>130.120954</td>\n",
       "      <td>105158245</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8631</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>-0.533800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date    open      high      low   close  adjusted_close     volume  \\\n",
       "0 2021-01-04  133.52  133.6116  126.760  129.41      127.519520  143301887   \n",
       "1 2021-01-05  128.89  131.7400  128.430  131.01      129.096146   97664898   \n",
       "2 2021-01-06  127.72  131.0499  126.382  126.60      124.750570  155087970   \n",
       "3 2021-01-07  128.36  131.6300  127.860  130.92      129.007461  109578157   \n",
       "4 2021-01-08  132.43  132.6300  130.230  132.05      130.120954  105158245   \n",
       "\n",
       "   dividend_amount  split_coefficient  close_percent_change company  \\\n",
       "0              0.0                1.0               -2.4719    AAPL   \n",
       "1              0.0                1.0                1.2364    AAPL   \n",
       "2              0.0                1.0               -3.3662    AAPL   \n",
       "3              0.0                1.0                3.4123    AAPL   \n",
       "4              0.0                1.0                0.8631    AAPL   \n",
       "\n",
       "   close_percent_change_new  \n",
       "0                 -1.533900  \n",
       "1                  0.427500  \n",
       "2                  0.303067  \n",
       "3                  0.650167  \n",
       "4                 -0.533800  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.toPandas().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "5ba68e0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-4.601700000000001"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-3.3662 + 1.2364 -2.4719 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0516b7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# source: https://stackoverflow.com/questions/71038595/pyspark-cumulative-sum-within-partition-for-moving-last-2-n-rows\n",
    "from pyspark.sql import functions as F, Window\n",
    "\n",
    "\n",
    "def window_all():\n",
    "    path = 'data/price_n_volume/2021/*.parquet'\n",
    "    df = spark.read \\\n",
    "        .option(\"header\", \"true\") \\\n",
    "        .parquet(path)\\\n",
    "        .drop('__index_level_0__')\n",
    "    w = Window.partitionBy('company').orderBy('date').rowsBetween(Window.currentRow, 2)\n",
    "\n",
    "    df = df.withColumn(\n",
    "        'close_percent_change_new', \n",
    "        F.avg('close_percent_change').over(w))\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "df_all = window_all()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "47bfe3ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|company|count|\n",
      "+-------+-----+\n",
      "|   AAPL|  252|\n",
      "|   AMGN|  252|\n",
      "|   AMZN|  252|\n",
      "|    ADI|  252|\n",
      "|    IBM|  252|\n",
      "|    AMD|  252|\n",
      "|   ABNB|  252|\n",
      "|    AEP|  252|\n",
      "|   ADBE|  252|\n",
      "|   ANSS|  252|\n",
      "|   ALGN|  252|\n",
      "+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_all.select(\\\n",
    "          col(\"company\")\n",
    "    ).groupBy('company').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5a8d1c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.createOrReplaceTempView(\"all_stocks\")\n",
    "df_appl = spark.sql(\"SELECT * FROM all_stocks WHERE company = 'AAPL'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0671b110",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test to check if df does not take into consideration other companies average \n",
    "\n",
    "False in (df_appl.toPandas().close_percent_change_new == df.toPandas().close_percent_change_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b5f5c141",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------------------------------+-----+\n",
      "|company|if_outlier_close_percent_change_20|count|\n",
      "+-------+----------------------------------+-----+\n",
      "|   AAPL|                             false|  558|\n",
      "|   AAPL|                              true|  264|\n",
      "|   ABNB|                              true|  193|\n",
      "|   ABNB|                             false|  387|\n",
      "|   ADBE|                             false|  553|\n",
      "|   ADBE|                              true|  265|\n",
      "|    ADI|                              true|  263|\n",
      "|    ADI|                             false|  559|\n",
      "|    AEP|                              true|  263|\n",
      "|    AEP|                             false|  559|\n",
      "|   ALGN|                              true|  244|\n",
      "|   ALGN|                             false|  574|\n",
      "|    AMD|                              true|  250|\n",
      "|    AMD|                             false|  568|\n",
      "|   AMGN|                              true|  246|\n",
      "|   AMGN|                             false|  576|\n",
      "|   AMZN|                             false|  566|\n",
      "|   AMZN|                              true|  252|\n",
      "|   ANSS|                              true|  277|\n",
      "|   ANSS|                             false|  545|\n",
      "+-------+----------------------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "\n",
    "def udf_if_outlier(val, avg, stddev):\n",
    "    try:\n",
    "        if ( val > (avg + stddev)) or ( val < (avg - stddev)):\n",
    "            return True\n",
    "    except Exception as e:\n",
    "        # print(f'e = {e}\\n val = {val}, avg = {avg}, stddev = {stddev}')\n",
    "        return False\n",
    "    return False\n",
    "\n",
    "def udf_if_outlier_high_only(val, avg, stddev):\n",
    "    try:\n",
    "        if ( val > (avg + stddev)):\n",
    "            return True\n",
    "    except Exception as e:\n",
    "        return False\n",
    "    return False\n",
    "\n",
    "\n",
    "def window_create(df, on_column ,number_of_days, both=1):\n",
    "    w = Window.partitionBy('company').orderBy('date').rowsBetween(Window.currentRow+1, number_of_days)\n",
    "    \n",
    "    avg_column = f'avg_{on_column}_{number_of_days}'\n",
    "    stddev_column = f'stddev_{on_column}_{number_of_days}'\n",
    "    outlier_column = f'if_outlier_{on_column}_{number_of_days}'\n",
    "\n",
    "    df = df.withColumn(\n",
    "        avg_column, \n",
    "        F.avg(f'{on_column}').over(w))\n",
    "    \n",
    "    df = df.withColumn(\n",
    "        stddev_column, \n",
    "        F.stddev(f'{on_column}').over(w))\n",
    "    \n",
    "    if both:\n",
    "        udfValueToOutlier = udf(udf_if_outlier, types.BooleanType())\n",
    "    else:\n",
    "        udfValueToOutlier = udf(udf_if_outlier_high_only, types.BooleanType())\n",
    "     \n",
    "    # here does not work\n",
    "    \n",
    "    df = df.withColumn(\n",
    "            outlier_column, \n",
    "            udfValueToOutlier(df[f'{on_column}'], df[f'{avg_column}'], df[f'{stddev_column}']))\n",
    "    \n",
    "    df.select(\\\n",
    "          col(\"company\"), col(outlier_column)\n",
    "    ).groupBy('company', outlier_column).count().orderBy(col(\"company\")).show()\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "path = 'data/price_n_volume/202*/*.parquet'\n",
    "df = spark.read \\\n",
    "        .option(\"header\", \"true\") \\\n",
    "        .parquet(path)\\\n",
    "        .drop('__index_level_0__')\n",
    "\n",
    "df = window_create(df, 'close_percent_change', 20)\n",
    "# df.toPandas().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f84caf9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------------------------------+-----+\n",
      "|company|if_outlier_close_percent_change_50|count|\n",
      "+-------+----------------------------------+-----+\n",
      "|   AAPL|                             false|  559|\n",
      "|   AAPL|                              true|  263|\n",
      "|   ABNB|                              true|  177|\n",
      "|   ABNB|                             false|  403|\n",
      "|   ADBE|                             false|  584|\n",
      "|   ADBE|                              true|  234|\n",
      "|    ADI|                              true|  261|\n",
      "|    ADI|                             false|  561|\n",
      "|    AEP|                              true|  260|\n",
      "|    AEP|                             false|  562|\n",
      "|   ALGN|                              true|  207|\n",
      "|   ALGN|                             false|  611|\n",
      "|    AMD|                              true|  250|\n",
      "|    AMD|                             false|  568|\n",
      "|   AMGN|                              true|  228|\n",
      "|   AMGN|                             false|  594|\n",
      "|   AMZN|                             false|  588|\n",
      "|   AMZN|                              true|  230|\n",
      "|   ANSS|                              true|  261|\n",
      "|   ANSS|                             false|  561|\n",
      "+-------+----------------------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "days = 50\n",
    "df = window_create(df, 'close_percent_change', days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2853d010",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+-----+\n",
      "|company|if_outlier_volume_50|count|\n",
      "+-------+--------------------+-----+\n",
      "|   AAPL|               false|  661|\n",
      "|   AAPL|                true|  161|\n",
      "|   ABNB|                true|   83|\n",
      "|   ABNB|               false|  497|\n",
      "|   ADBE|               false|  683|\n",
      "|   ADBE|                true|  135|\n",
      "|    ADI|                true|  132|\n",
      "|    ADI|               false|  690|\n",
      "|    AEP|                true|  104|\n",
      "|    AEP|               false|  718|\n",
      "|   ALGN|                true|  113|\n",
      "|   ALGN|               false|  705|\n",
      "|    AMD|                true|  147|\n",
      "|    AMD|               false|  671|\n",
      "|   AMGN|                true|   93|\n",
      "|   AMGN|               false|  729|\n",
      "|   AMZN|               false|  693|\n",
      "|   AMZN|                true|  125|\n",
      "|   ANSS|                true|  132|\n",
      "|   ANSS|               false|  690|\n",
      "+-------+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "days = 50\n",
    "df = window_create(df, 'volume', days, both=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "65257dc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------------------+-----+\n",
      "|company|if_outlier_volume_100|count|\n",
      "+-------+---------------------+-----+\n",
      "|   AAPL|                false|  660|\n",
      "|   AAPL|                 true|  162|\n",
      "|   ABNB|                 true|   69|\n",
      "|   ABNB|                false|  511|\n",
      "|   ADBE|                false|  696|\n",
      "|   ADBE|                 true|  122|\n",
      "|    ADI|                 true|  116|\n",
      "|    ADI|                false|  706|\n",
      "|    AEP|                 true|   90|\n",
      "|    AEP|                false|  732|\n",
      "|   ALGN|                 true|  102|\n",
      "|   ALGN|                false|  716|\n",
      "|    AMD|                 true|  134|\n",
      "|    AMD|                false|  684|\n",
      "|   AMGN|                 true|   85|\n",
      "|   AMGN|                false|  737|\n",
      "|   AMZN|                false|  703|\n",
      "|   AMZN|                 true|  115|\n",
      "|   ANSS|                 true|  128|\n",
      "|   ANSS|                false|  694|\n",
      "+-------+---------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "days = 100\n",
    "df = window_create(df, 'volume', days, both=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "54d9670f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------------------+-----+\n",
      "|company|if_outlier_volume_200|count|\n",
      "+-------+---------------------+-----+\n",
      "|   AAPL|                false|  667|\n",
      "|   AAPL|                 true|  155|\n",
      "|   ABNB|                 true|   70|\n",
      "|   ABNB|                false|  510|\n",
      "|   ADBE|                false|  707|\n",
      "|   ADBE|                 true|  111|\n",
      "|    ADI|                 true|  116|\n",
      "|    ADI|                false|  706|\n",
      "|    AEP|                 true|   94|\n",
      "|    AEP|                false|  728|\n",
      "|   ALGN|                 true|  104|\n",
      "|   ALGN|                false|  714|\n",
      "|    AMD|                 true|  150|\n",
      "|    AMD|                false|  668|\n",
      "|   AMGN|                 true|   87|\n",
      "|   AMGN|                false|  735|\n",
      "|   AMZN|                false|  696|\n",
      "|   AMZN|                 true|  122|\n",
      "|   ANSS|                 true|  134|\n",
      "|   ANSS|                false|  688|\n",
      "+-------+---------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "days = 200\n",
    "df = window_create(df, 'volume', days, both=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ef6f9e",
   "metadata": {},
   "source": [
    "![Outlier](https://upload.wikimedia.org/wikipedia/commons/thumb/8/8c/Standard_deviation_diagram.svg/1920px-Standard_deviation_diagram.svg.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e4e9f0d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1\n"
     ]
    }
   ],
   "source": [
    "def udf_if_outlier(val, avg, stddev):\n",
    "    if ( val > (avg + stddev)) or ( val < (avg - stddev)):\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "print(udf_if_outlier(0.8, 1, 0.1),udf_if_outlier(1.2, 1, 0.1) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c0e88234",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa8a077",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
